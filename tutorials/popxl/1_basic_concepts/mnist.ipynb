{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notebook autogenerated from mnist.py on 22-Jul-2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PopXL and popxl.addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As an alternative to using the ONNX builder to create models, PopXL is an\n",
    "experimental PopART Python module which allows users to hand-craft arbitrary\n",
    "computational graphs, control execution schemes, and optimise the Poplar\n",
    "executable. This provides greater flexibility than is possible using the\n",
    "standard PopART API.\n",
    "\n",
    "It gives precise control of program size and runtime performance in a high level\n",
    "language (Python). It is useful for large models, as it gives low-level control\n",
    "of:\n",
    "\n",
    "- Subgraph inlining/outlining for optimising program size\n",
    "- Data parallelism for improving throughput\n",
    "- Remote Variables for streaming/storing data remotely to optimise memory\n",
    "  requirements of the model\n",
    "\n",
    "Familiarity with the basic [PopXL\n",
    "concepts](https://docs.graphcore.ai/projects/popxl/en/3.1.0/concepts.html#concepts)\n",
    "will be helpful, but not essential:\n",
    "\n",
    "- Intermediate representation\n",
    "  ([IR](https://docs.graphcore.ai/projects/popxl/en/3.1.0/concepts.html#irs))\n",
    "- Tensors (variable, constant and intermediate)\n",
    "- [Graphs](https://docs.graphcore.ai/projects/popxl/en/3.1.0/concepts.html#graphs)\n",
    "  (main and subgraph)\n",
    "- Input and output streams\n",
    "- Sessions\n",
    "\n",
    "popxl.addons includes common usage patterns of PopXL. It simplifies the process\n",
    "of building and training a model while keeping control of execution and\n",
    "optimisation strategies.\n",
    "\n",
    "Once you've finished this tutorial, you will:\n",
    "\n",
    "- Be familiar with `addons` basic concepts and understand relations between them:\n",
    "  - `Module`\n",
    "  - `NamedTensors`\n",
    "  - `VariableFactory` and `NamedVariableFactories`\n",
    "  - `GraphWithNamedArgs`\n",
    "  - `BoundGraph`\n",
    "  - Transforms\n",
    "- Understand what **outlining** is and write an outlined model.\n",
    "- Use `addons` `autodiff` transform to obtain the backward graph for your model.\n",
    "- Write a simple training + test program, copying trained weights from the\n",
    "  training session to the test session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the Jupyter notebook version of this tutorial:\n",
    "\n",
    "1. Install a Poplar SDK (version 2.6 or later) and source the enable.sh scripts\n",
    "   for both PopART and Poplar as described in the [Getting Started\n",
    "   guide](https://docs.graphcore.ai/en/latest/getting-started.html) for your IPU\n",
    "   system\n",
    "2. Create a virtual environment\n",
    "3. In the same virtual environment, install the Jupyter notebook server: `python\n",
    "   -m pip install jupyter`\n",
    "4. Launch a Jupyter Server on a specific port: `jupyter-notebook --no-browser\n",
    "   --port <port number>`. Be sure to be in the virtual environment.\n",
    "5. Connect via SSH to your remote machine, forwarding your chosen port: `ssh -NL\n",
    "   <port number>:localhost:<port number> <your username>@<remote machine>`\n",
    "\n",
    "For more details about this process, or if you need troubleshooting, see our\n",
    "[guide on using IPUs from Jupyter\n",
    "notebooks](../../standard_tools/using_jupyter/README.md).\n",
    "\n",
    "If using VS Code, Intellisense can help you understand the tutorial code. It\n",
    "will show function and class descriptions when hovering over their names and\n",
    "lets you easily jump to their definitions. Consult the [VSCode setup\n",
    "guide](../VSCodeSetup.md) to use Intellisense for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "sst_ignore_md",
     "sst_ignore_code_only",
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "%pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "The following are basic concepts of popxl.addons:\n",
    "\n",
    "- `Module`: a module is the base class to build layers and models. It is similar\n",
    "  to a PyTorch Module or a Keras Layer. It allows you to create a **graph** with\n",
    "  **state**, which means with internal parameters (such as weights). Graphs can\n",
    "  be called from multiple places in parent graphs, which reduces code\n",
    "  duplication.\n",
    "- `NamedTensors` : a `DotTree` collection of `popxl.Tensor`, which is basically\n",
    "  a dictionary between names and tensors. `DotTree` are used in `addons` for all\n",
    "  collections of named objects. They are very useful to group objects in\n",
    "  namespaces.\n",
    "- `VariableFactory` and `NamedVariableFactories` (a `DotTree` collection of\n",
    "  factories): factories are used to delay variable instantiation to the main\n",
    "  graph.\n",
    "- `GraphWithNamedArgs`: it is a container of a `popxl.Graph` and `NamedTensors`.\n",
    "  `NamedTensors` are the graph named inputs. When a `GraphWithNamedArgs` is\n",
    "  created with `Module.create_graph()`, factories for each of the input tensors\n",
    "  are instantiated as well.\n",
    "- `transforms` are functions that directly modify the graph, generating a new\n",
    "  one. An example is the `addons.autodiff` transform, which, given a graph,\n",
    "  produces the corresponding backward graph.\n",
    "- `BoundGraph`: it is a container of a `popxl.Graph` and a `TensorMap` of bound\n",
    "  Tensor inputs, which are automatically provided as inputs when the graph is\n",
    "  called.\n",
    "\n",
    "The figure below shows how these concepts are related in a typical popxl.addons\n",
    "workflow:\n",
    "\n",
    "![Figure 1](images/workflow.png)\n",
    "\n",
    "**Figure 1:** Workflow in popxl.addons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple example\n",
    "\n",
    "### Imports\n",
    "\n",
    "First let's import all the packages we are going to need, including `popxl` and\n",
    "`popxl_addons`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Mapping, Optional\n",
    "from functools import partial\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "import popxl.ops as ops\n",
    "import popxl_addons as addons\n",
    "import popxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Linear Module\n",
    "\n",
    "Below is an example of a linear layer implemented by subclassing\n",
    "`addons.Module`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(addons.Module):\n",
    "    def __init__(self, out_features: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.bias = bias\n",
    "\n",
    "    def build(self, x: popxl.Tensor) -> popxl.Tensor:\n",
    "        # add a state variable to the module\n",
    "        w = self.add_variable_input(\n",
    "            \"weight\",\n",
    "            partial(np.random.normal, 0, 0.02, (x.shape[-1], self.out_features)),\n",
    "            x.dtype,\n",
    "        )\n",
    "        y = x @ w\n",
    "        if self.bias:\n",
    "            # add a state variable to the module\n",
    "            b = self.add_variable_input(\"bias\", partial(np.zeros, y.shape[-1]), x.dtype)\n",
    "            y = y + b\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Module needs to implement a `build` method. Here you actually define the\n",
    "graph,  specifying inputs, operations and outputs (the return values).\n",
    "\n",
    "Inputs are added in two different ways:\n",
    "\n",
    "- **named inputs** (the parameters of the model, its state) are added via the\n",
    "  `add_variable_input` method (`w` and `b` above).\n",
    "- All tensor arguments of the `build` method (`x` in the example above) become\n",
    "  inputs of the graph.\n",
    "\n",
    "PopXL variables (the parameters of the model) can only live in the main graph\n",
    "which means state tensor variables cannot be instantiated directly in the\n",
    "subgraph; their creation needs to take place in the main graph. The\n",
    "`add_variable_input` method creates a named local placeholder (a local tensor)\n",
    "and a corresponding `VariableFactory`. As we will see below, the factory is used\n",
    "to instantiate a variable in the main graph and then bind it to the named input\n",
    "in the subgraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a graph from a Module\n",
    "\n",
    "Before we construct any graphs we need to define a `popxl.Ir` instance which\n",
    "will hold the main graph. This will represent your fully compiled program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = popxl.Ir(replication=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the IR main graph we construct the `Linear` graph as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ir.main_graph:\n",
    "    # create a variable factory and a graph from the module\n",
    "    facts, linear_graph = Linear(32).create_graph(\n",
    "        popxl.TensorSpec((2, 4), popxl.float32)\n",
    "    )\n",
    "    print(\"factories: \\n\", facts)\n",
    "    print(\"\\n graph: \\n\", linear_graph.print_schedule())\n",
    "\n",
    "    # since we are in the main graph, we can instantiate variables using the factories\n",
    "    variables = facts.init()\n",
    "    print(\"\\n variables: \\n\", variables)\n",
    "\n",
    "    # and bind our graph to these variables that live in the main graph.\n",
    "    bound_graph = linear_graph.bind(variables)\n",
    "\n",
    "    # the bound graph can be called providing only unnamed inputs x\n",
    "    input_data = np.asarray(np.random.rand(2, 4)).astype(np.float32)\n",
    "    input_tensor = popxl.variable(input_data, name=\"x\")\n",
    "\n",
    "    out = bound_graph.call(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_graph` method requires a `TensorSpec` object or a `Tensor` object\n",
    "for each of the unnamed inputs (`x`) and returns a `GraphWithNamedArgs` and\n",
    "`NamedVariableFactories` for the named inputs.\n",
    "\n",
    "The `GraphWithNamedArgs` gathers together a `popxl.Graph` and tensors\n",
    "(`GraphWithNamedArgs.args`) which correspond to the named inputs we added\n",
    "earlier with `add_variable_input` when we defined the Linear Module.\n",
    "\n",
    "Also, the `NamedVariableFactories` collection contains a factory for each of\n",
    "those tensors. Instantiating a variable in the main graph is optional, provided\n",
    "you feed these inputs at the call site. E.g. `linear_graph.call(x,w,b)`\n",
    "\n",
    "Once you have instantiated variables using these factories, you can bind the\n",
    "graph to them using `bound_graph = linear_graph.bind(variables)`.\n",
    "\n",
    "The resulting `BoundGraph` is effectively a graph with an internal state, which\n",
    "can be called from the main graph with:\n",
    "\n",
    "```python\n",
    "outputs = bound_graph.call(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we specify the properties of the IR and create a session object to run\n",
    "it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir.num_host_transfers = 1\n",
    "\n",
    "# Create a session to run your IR\n",
    "session = popxl.Session(ir, \"ipu_hw\")\n",
    "\n",
    "# Run the program\n",
    "with session:\n",
    "    session.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary and concepts in practice\n",
    "\n",
    "In summary, the basic steps needed to build and run a model in popxl.addons are\n",
    "the following:\n",
    "\n",
    "1. Subclass `addons.Module` to create your layers and models in an\n",
    "   object-oriented fashion.\n",
    "2. Initialise an IR as ``ir`` which represents your full compiled program.\n",
    "3. In the `ir.main_graph()` context, generate the computational graph and the\n",
    "   variable factories associated with your module with the `Module`\n",
    "   `create_graph` method.\n",
    "4. In the `ir.main_graph()` context, instantiate actual variables with the\n",
    "   `NamedVariableFactory` `init` method.\n",
    "5. In the `ir.main_graph()` context, bind the computational graph to the\n",
    "   variables using the `bind` method of ``GraphWithNamedArgs`.\n",
    "6. In the `ir.main_graph()` context,  call the bound graph providing only the\n",
    "   inputs.\n",
    "7. Specify the properties of the IR and create a `popxl.Session` to run your IR.\n",
    "8. Run the program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple bound graphs\n",
    "\n",
    "The same subgraph can be bound to different sets of parameters, resulting in\n",
    "different bound graphs. You can think to a bound graph as a container of a graph\n",
    "object and a set of variables. Two different bound graphs can reference to the\n",
    "same graph, but have different variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = popxl.Ir()\n",
    "with ir.main_graph:\n",
    "    facts, linear_graph = Linear(32).create_graph(\n",
    "        popxl.TensorSpec((2, 4), popxl.float32)\n",
    "    )\n",
    "\n",
    "    variables1 = facts.init()\n",
    "    variables2 = facts.init()\n",
    "\n",
    "    # the same subgraph can be bound to different variables,\n",
    "    # generating distinct bound graph objects.\n",
    "    bound_graph1 = linear_graph.bind(variables1)\n",
    "    bound_graph2 = linear_graph.bind(variables2)\n",
    "\n",
    "    print(\"\\n two different bound graphs: \\n\", bound_graph1, bound_graph2)\n",
    "\n",
    "    input_data = np.asarray(np.random.rand(2, 4)).astype(np.float32)\n",
    "    input_tensor = popxl.variable(input_data, name=\"x\")\n",
    "\n",
    "    out = bound_graph1.call(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both bound graphs refer to the same computational graph, hence code is reused on\n",
    "the IPU.\n",
    "\n",
    "What actually happens is that `bound_graph1.call` becomes a call operation in\n",
    "the main graph with the following arguments:\n",
    "\n",
    "```python\n",
    "call(graph, x, inputs_dict=variables_dict1)\n",
    "```\n",
    "\n",
    "where `variables_dict1` is a dictionary between the local tensors in the graph\n",
    "and the corresponding variables in the main graph, created using the factories.\n",
    "\n",
    "Calling `bound_graph2`, which is the same graph but bound to different\n",
    "parameters, results in:\n",
    "\n",
    "```python\n",
    "call(graph, x, inputs_dict=variables_dict2)\n",
    "```\n",
    "\n",
    "![Figure 2](images/module_graph_bgraph.png)\n",
    "\n",
    "**Figure 2:** The `module.create_graph` method generates a graph and named\n",
    "variable factories. Calling `.init()` on the variable factories instantiates\n",
    "actual variable tensors in the main graph. The same subgraph can be bound to\n",
    "different sets of variables, generating different bound graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Modules and Outlining\n",
    "\n",
    "Outlining is the opposite of inlining:\n",
    "\n",
    "- Inlining, which is generally the default behaviour on the IPU means that if a\n",
    "  module is used more than once in a model, then a copy will be made of the code\n",
    "  on the IPU for each use. This has the effect of better performance, because we\n",
    "  remove some of the  overhead of calling out to a function, but will use more\n",
    "  always-live memory due to code duplication.\n",
    "- Outlining, conversely requires some explicit PopXL code. Code will only exist\n",
    "  once on each IPU and could be called from multiple parent models. This has the\n",
    "  effect of reducing total memory requirements at the expense of some\n",
    "  performance.\n",
    "\n",
    "Further information on graph outlining can be found in our [memory performance\n",
    "optimisation\n",
    "guide](https://docs.graphcore.ai/projects/memory-performance-optimisation/en/3.1.0/common-memory-optimisations.html#graph-outlining).\n",
    "\n",
    "These concepts becomes important when we start building more complicated models\n",
    "using the\n",
    "[`Module`](https://docs.graphcore.ai/projects/popxl/en/3.1.0/api.html#modules)\n",
    "api, combining and nesting several modules. To see why, let's build a simple\n",
    "linear model using several `Linear` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(addons.Module):\n",
    "    def __init__(self, cache: Optional[addons.GraphCache] = None):\n",
    "        super().__init__(cache=cache)\n",
    "        self.fc1 = Linear(512)\n",
    "        self.fc2 = Linear(512)\n",
    "        self.fc3 = Linear(512)\n",
    "        self.fc4 = Linear(10)\n",
    "\n",
    "    def build(self, x: popxl.Tensor):\n",
    "        x = x.reshape((-1, 28 * 28))\n",
    "        x = ops.gelu(self.fc1(x))\n",
    "        x = ops.gelu(self.fc2(x))\n",
    "        x = ops.gelu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "ir = popxl.Ir()\n",
    "main = ir.main_graph\n",
    "with main:\n",
    "    facts, net_graph = Net().create_graph(popxl.TensorSpec((28, 28), popxl.float32))\n",
    "    print(facts.to_dict().keys())\n",
    "    print(\"\\n\", net_graph.print_schedule())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the output of `print_schedule()` that nested modules lead to\n",
    "**inlined** code: the nodes are repeated for each layer, even if they are\n",
    "identical. For example here `fc2` and `fc3` have the exact same graph. If you\n",
    "want to achieve better code reuse you can manually **outline** the graph by\n",
    "explicitly inserting call operations.\n",
    "\n",
    "To implement outlining using the `Module` class, you need to:\n",
    "\n",
    "- Create the graph you want to outline with `factories, shared_graph =\n",
    "  module.create_graph()`.\n",
    "- Generate different named input tensors (different local placeholders) for each\n",
    "  layer. To do this, you can use the `module.add_variable_inputs(name,\n",
    "  factories)` method. Every time you call this function, you create distinct\n",
    "  **local** tensors. Moreover, you add factories for these tensors.\n",
    "- Bind the graph to each set of local tensors, obtaining a different\n",
    "  `BoundGraph` for each layer.\n",
    "- Add call operations to the bound graphs.\n",
    "\n",
    "When you call `factories.init()` in the main context you generate variables for\n",
    "all the local tensors. When you finally bind the graph, the local tensors are\n",
    "bound to the main variables. Since the `shared_graph` is bound to the local\n",
    "tensors, it is effectively bound to them too.\n",
    "\n",
    "Below is an outlined version of the network. You can see in the graph that the\n",
    "`fc2` and `fc3` blocks have been replaced by `call` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetOutlined(addons.Module):\n",
    "    def __init__(self, cache: Optional[addons.GraphCache] = None):\n",
    "        super().__init__(cache=cache)\n",
    "        # first and last layer are not reused\n",
    "        self.fc1 = Linear(512)\n",
    "        self.fc4 = Linear(10)\n",
    "\n",
    "    def build(self, x: popxl.Tensor):\n",
    "        x = x.reshape((-1, 28 * 28))\n",
    "        x = ops.gelu(self.fc1(x))\n",
    "\n",
    "        # create a single subgraph to be used both for fc2 and fc3\n",
    "        # create variable factories and subgraph\n",
    "        facts, subgraph = Linear(512).create_graph(x)\n",
    "        # generate specific named inputs for fc2\n",
    "        named_tensors_0 = self.add_variable_inputs(\"fc2\", facts)\n",
    "        # fc2 is a bound graph using the shared, single subgraph and custom params\n",
    "        fc2 = subgraph.bind(named_tensors_0)\n",
    "        # generate specific named inputs for fc3\n",
    "        named_tensors_1 = self.add_variable_inputs(\"fc3\", facts)\n",
    "        # fc3 is a bound graph using the shared, single subgraph and custom params\n",
    "        fc3 = subgraph.bind(named_tensors_1)\n",
    "\n",
    "        (x,) = fc2.call(x)\n",
    "        x = ops.gelu(x)\n",
    "        (x,) = fc3.call(x)\n",
    "        x = ops.gelu(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "ir = popxl.Ir()\n",
    "with ir.main_graph:\n",
    "    args, net_graph = NetOutlined().create_graph(\n",
    "        popxl.TensorSpec((28, 28), popxl.float32)\n",
    "    )\n",
    "    print(args.to_dict().keys())\n",
    "    print(\"\\n\", net_graph.print_schedule())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DotTree example\n",
    "\n",
    "The following code block is a simple example to help you get familiar with the\n",
    "`DotTree` syntax used by popxl.addons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = popxl.Ir(replication=1)\n",
    "\n",
    "with ir.main_graph:\n",
    "    facts, linear_graph = Linear(32).create_graph(\n",
    "        popxl.TensorSpec((2, 4), popxl.float32)\n",
    "    )\n",
    "    variables = facts.init()\n",
    "    variables2 = facts.init()\n",
    "\n",
    "    print(\"----- DotTree functionalities -----\\n\")\n",
    "    collection = addons.NamedTensors()  # empty collection\n",
    "    collection.insert(\"layer1\", variables)  # add a new key with the insert method\n",
    "    collection.insert(\"layer2\", variables2)\n",
    "    print(\n",
    "        \"A nested collection: the nested structure appear from the dot structure of names\"\n",
    "    )\n",
    "    print(collection, \"\\n\")  # nested structure\n",
    "    print(\"Each leaf can be accessed with dot syntax: collection.layer1\")\n",
    "    print(\n",
    "        collection.layer1\n",
    "    )  # each leaf node in the tree can be accessed with dot syntax\n",
    "    collection_dict = collection.to_dict()  # convert the collection to dictionary\n",
    "\n",
    "    nt = addons.NamedTensors.from_dict(\n",
    "        {\"x\": input_tensor}\n",
    "    )  # create the collection from a dictionary\n",
    "    nt_b = addons.NamedTensors.from_dict({\"b\": variables.bias})\n",
    "    nt.update(\n",
    "        nt_b\n",
    "    )  # update the collection with another collection, keys should not repeat\n",
    "    # print(\"\\n\",nt)\n",
    "\n",
    "    names = [\"new_bias_name\", \"new_weight_name\"]\n",
    "    nt_from_lists = addons.NamedTensors.pack(\n",
    "        names, variables.tensors\n",
    "    )  # create the collection from a list\n",
    "    names, tensors = nt_from_lists.unpack()\n",
    "    # print(\"\\n\",nt_from_lists)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # ----- NamedTensors specific -----\n",
    "    print(\"----- NamedTensors -----\\n\")\n",
    "    print(collection.named_tensors, \"\\n\")  # same as to_dict, specific of NamedTensors\n",
    "    print(\"Get only tensors, sorted by name\")\n",
    "    print(collection.tensors)  # returns tensors, sorted by names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with the above code to explore the api before going through\n",
    "the full MNIST program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "We are now ready to build the full program to train and validate a linear model\n",
    "on the MNIST dataset.\n",
    "\n",
    "First of all, we need to load the dataset. We are going to use a PyTorch\n",
    "DataLoader. Data is normalised using the mean and std deviation of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "def get_mnist_data(test_batch_size: int, batch_size: int):\n",
    "    training_data = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST(\n",
    "            \"~/.torch/datasets\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    # mean and std computed on the training set.\n",
    "                    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    validation_data = torch.utils.data.DataLoader(\n",
    "        torchvision.datasets.MNIST(\n",
    "            \"~/.torch/datasets\",\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=torchvision.transforms.Compose(\n",
    "                [\n",
    "                    torchvision.transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    return training_data, validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Training step\n",
    "\n",
    "Now that we have a dataset and a model we are ready to construct the training\n",
    "program.\n",
    "\n",
    "First of all let's define a function to build the training program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_program(batch_size, device, learning_rate):\n",
    "    ir = popxl.Ir(replication=1)\n",
    "\n",
    "    with ir.main_graph:\n",
    "        # Create input streams from host to device\n",
    "        img_stream = popxl.h2d_stream((batch_size, 28, 28), popxl.float32, \"image\")\n",
    "        img_t = ops.host_load(img_stream)  # load data\n",
    "        label_stream = popxl.h2d_stream((batch_size,), popxl.int32, \"labels\")\n",
    "        labels = ops.host_load(label_stream, \"labels\")\n",
    "\n",
    "        # Create forward graph\n",
    "        facts, fwd_graph = Net().create_graph(img_t)\n",
    "        # Create backward graph via autodiff transform\n",
    "        bwd_graph = addons.autodiff(fwd_graph)\n",
    "\n",
    "        # Initialise variables (weights)\n",
    "        variables = facts.init()\n",
    "\n",
    "        # Call the forward graph with call_with_info because we want to retrieve\n",
    "        # information from the call site\n",
    "        fwd_info = fwd_graph.bind(variables).call_with_info(img_t)\n",
    "        x = fwd_info.outputs[0]  # forward output\n",
    "\n",
    "        # Compute loss and starting gradient for backpropagation\n",
    "        loss, dx = addons.ops.cross_entropy_with_grad(x, labels)\n",
    "\n",
    "        # Setup a stream to retrieve loss values from the host\n",
    "        loss_stream = popxl.d2h_stream(loss.shape, loss.dtype, \"loss\")\n",
    "        ops.host_store(loss_stream, loss)\n",
    "\n",
    "        # retrieve activations from the forward graph\n",
    "        activations = bwd_graph.grad_graph_info.inputs_dict(fwd_info)\n",
    "        # call the backward graph providing the starting value for backpropagation and activations\n",
    "        bwd_info = bwd_graph.call_with_info(dx, args=activations)\n",
    "\n",
    "        # Optimiser: get a mapping between forward tensors and corresponding\n",
    "        # gradients and use it to update each tensor\n",
    "        grads_dict = bwd_graph.grad_graph_info.fwd_parent_ins_to_grad_parent_outs(\n",
    "            fwd_info, bwd_info\n",
    "        )\n",
    "        for t in variables.tensors:\n",
    "            ops.scaled_add_(t, grads_dict[t], b=-learning_rate)\n",
    "\n",
    "    ir.num_host_transfers = 1\n",
    "    return popxl.Session(ir, device), [img_stream, label_stream], variables, loss_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the `replication_factor` for the IR before constructing the\n",
    "program, because some operations need to know the number of IPUs involved.\n",
    "\n",
    "Inside the main graph context of the IR, we construct\n",
    "[streams](https://docs.graphcore.ai/projects/popxl/en/3.1.0/op.html#data-input-and-output)\n",
    "to transfer input data from the host to the device (`popxl.h2d_stream`) and we\n",
    "load data to the device (`popxl.host_load`).\n",
    "\n",
    "Then, we create two graphs: one for the forward pass and one for the backward\n",
    "pass. The latter can be obtained from the forward graph applying a\n",
    "**transform**, which is a way of making changes at the graph level. The\n",
    "`addons.autodiff` transform is the one we need. It is basically\n",
    "[popxl.autodiff](https://docs.graphcore.ai/projects/popxl/en/3.1.0/transforms.html#autodiff)\n",
    "with some additional patterns.\n",
    "\n",
    "We instantiate the weights of the network (`variables = facts.init()`), bind the\n",
    "forward graph to these variables and make the call to the forward graph. We use\n",
    "`call_with_info` because we want to be able to retrieve the activations from the\n",
    "forward graph and pass them to the backward graph (see\n",
    "[calling-a-subgraph](https://docs.graphcore.ai/projects/popxl/en/3.1.0/graph.html#calling-a-subgraph))\n",
    "\n",
    "The `cross_entropy_with_grad` operation returns the loss tensor and the gradient\n",
    "to start backpropagation, which is 1 (dl/dl) unless you specify the additional\n",
    "argument `loss_scaling`.\n",
    "\n",
    "We create an output stream from the device to the host in order to retrieve loss\n",
    "values.\n",
    "\n",
    "We call the backward graph and retrieve a dictionary mapping each tensor in the\n",
    "forward graph to its corresponding gradient in the backward graph with\n",
    "`fwd_parent_ins_to_grad_parent_outs`. This dictionary can then be used by the\n",
    "optimiser to update the weights of the model.\n",
    "\n",
    "Finally, we setup the properties for `ir`, specifying `num_host_transfers`, and\n",
    "we return a `popxl.Session` so that we can execute our program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct the model using the following hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "test_batch_size = 80\n",
    "device = \"ipu_hw\"\n",
    "learning_rate = 0.05\n",
    "epochs = 1\n",
    "\n",
    "training_data, test_data = get_mnist_data(test_batch_size, train_batch_size)\n",
    "\n",
    "train_session, train_input_streams, train_variables, loss_stream = train_program(\n",
    "    train_batch_size, device, learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And train it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = len(training_data)\n",
    "with train_session:\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        print(f\"Epoch {epoch}/{epochs}\")\n",
    "        bar = tqdm(training_data, total=num_batches)\n",
    "        for data, labels in bar:\n",
    "            inputs: Mapping[popxl.HostToDeviceStream, np.ndarray] = dict(\n",
    "                zip(train_input_streams, [data.squeeze().float(), labels.int()])\n",
    "            )\n",
    "            loss = train_session.run(inputs)[loss_stream]\n",
    "            bar.set_description(f\"Loss:{loss:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training we retrieve the trained weights to use them during inference and test the accuracy of the model.\n",
    "To do that, we need to get the data stored in the tensor on the device with `get_tensors_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars_to_data = train_session.get_tensors_data(train_variables.tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "To test our model we need to create an inference-only program and run it on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_program(test_batch_size, device):\n",
    "    ir = popxl.Ir(replication=1)\n",
    "\n",
    "    with ir.main_graph:\n",
    "        # Inputs\n",
    "        in_stream = popxl.h2d_stream((test_batch_size, 28, 28), popxl.float32, \"image\")\n",
    "        in_t = ops.host_load(in_stream)\n",
    "\n",
    "        # Create graphs\n",
    "        facts, graph = Net().create_graph(in_t)\n",
    "\n",
    "        # Initialise variables\n",
    "        variables = facts.init()\n",
    "\n",
    "        # Forward\n",
    "        (outputs,) = graph.bind(variables).call(in_t)\n",
    "        out_stream = popxl.d2h_stream(outputs.shape, outputs.dtype, \"outputs\")\n",
    "        ops.host_store(out_stream, outputs)\n",
    "\n",
    "    ir.num_host_transfers = 1\n",
    "    return popxl.Session(ir, device), [in_stream], variables, out_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we initialise the IR.\n",
    "Then, we define the input stream, the graph and the factories for the variables.\n",
    "We instantiate the variables and bind the graph to them, obtaining our bound graph.\n",
    "Finally, we call the model. Since this time we do not need to retrieve\n",
    "information from the call site, we can simply use `call` instead of\n",
    "`call_with_info`.\n",
    "We store the output in an output stream for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now call the function to create the test program and initialise the session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session, test_input_streams, test_variables, out_stream = test_program(\n",
    "    test_batch_size, device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run, we need to initialise the model variables with the weights we\n",
    "trained earlier.\n",
    "\n",
    "To do that, once the test_session is created we can call\n",
    "`test_session.write_variables_data`. This function requires a dictionary `\n",
    "tensor_to_be_written : tensor_data_to_write `.\n",
    "It makes a call to `test_session.write_variable_data(tensor,tensor_data)` for\n",
    "each tensor in the dictionary and then makes a single host to device transfer at\n",
    "the end to send all data in one go.\n",
    "In our case, `tensor_to_be_written` needs to be the `test_session` variables,\n",
    "and `tensor_data_to_write` needs to be the tensor values, given as numpy arrays.\n",
    "\n",
    "We already have a dictionary between `train_session` variables and their values,\n",
    "the `train_weights_data_dict` retrieved with `train_session.get_tensor_data`.\n",
    "\n",
    "We need a dictionary between the `test_session` variables and the\n",
    "`train_session` variables, so that we can create the required `test_variables :\n",
    "test_variables_data` dictionary.\n",
    "\n",
    "Provided test and training variables have the same names, we can use the\n",
    "`DotTree.to_mapping` function to create this mapping. Given two DotTrees, for\n",
    "common keys this function creates a dictionary of their values. So,\n",
    "`train_variables.to_mapping(test_variables)` returns a dictionary `popxl.Tensor\n",
    ": popxl.Tensor`, where each key-value pair is made of a train variable and the\n",
    "test variable with the same name.\n",
    "\n",
    "With these two dictionaries, we can finally build the required `test_variables :\n",
    "test_variables_data` dictionary.\n",
    "\n",
    "Earlier we saved the trained weights to `train_vars_to_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary { train_session variables : test_session variables }\n",
    "train_vars_to_test_vars = train_variables.to_mapping(test_variables)\n",
    "\n",
    "# Create a dictionary { test_session variables : tensor data (numpy) }\n",
    "test_vars_to_data = {\n",
    "    test_var: train_vars_to_data[train_var].copy()\n",
    "    for train_var, test_var in train_vars_to_test_vars.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call `.copy` on each tensor because `get_tensors_data` returns a memory view\n",
    "of the data. This may become invalid if the session is invalidated (or it may\n",
    "change if we do something else later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy trained weights to the program, with a single host to device transfer\n",
    "test_session.write_variables_data(test_vars_to_data)\n",
    "\n",
    "# check that weights have been copied correctly\n",
    "test_vars_to_data_after_write = test_session.get_tensors_data(test_variables.tensors)\n",
    "for test_var, array in test_vars_to_data_after_write.items():\n",
    "    assert (array == test_vars_to_data[test_var]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can run the model and evaluate accuracy from the predictions of the\n",
    "model.\n",
    "The predictions do not need to be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions: np.ndarray, labels: np.ndarray):\n",
    "    ind = np.argmax(predictions, axis=-1).flatten()\n",
    "    labels = labels.detach().numpy().flatten()\n",
    "    return np.mean(ind == labels) * 100.0\n",
    "\n",
    "\n",
    "num_batches = len(test_data)\n",
    "sum_acc = 0.0\n",
    "with test_session:\n",
    "    for data, labels in tqdm(test_data, total=num_batches):\n",
    "        inputs: Mapping[popxl.HostToDeviceStream, np.ndarray] = dict(\n",
    "            zip(test_input_streams, [data.squeeze().float(), labels.int()])\n",
    "        )\n",
    "        output = test_session.run(inputs)\n",
    "        sum_acc += accuracy(output[out_stream], labels)\n",
    "\n",
    "test_set_accuracy = sum_acc / len(test_data)\n",
    "print(f\"Accuracy on test set: {test_set_accuracy:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial we explored the new PopXL API. We achieved the following:\n",
    "\n",
    "- built a simple Linear model (by subclassing `addons.Module`) and ran it.\n",
    "- created a multi-layer model with subgraphs and explored outlining. Outlining\n",
    "  reduces program size by compiling subgraphs as callable functions rather than\n",
    "  inlined code. We constructed subgraphs using `create_graph()` and bound them\n",
    "  explicitly to make 2 layers of a network.\n",
    "- explored the DotTree syntax which is useful for accessing elements of the\n",
    "  model and creating connections.\n",
    "- built and trained a full MNIST model. The gradients were calculated with the\n",
    "  `addons.autodiff` transform applied to the forward computational graph.\n",
    "\n",
    "We will re-use the `addons.Module` class, in another tutorial, when we make a\n",
    "[custom optimiser](../2_custom_optimiser).\n",
    "\n",
    "To try out more features in PopXL [look at our other\n",
    "tutorials](../../README.md).\n",
    "\n",
    "You can also read our [PopXL User\n",
    "Guide](https://docs.graphcore.ai/projects/popxl/en/3.1.0/) for more\n",
    "information.\n",
    "\n",
    "As the PopXL API is still experimental, we would love to hear your feedback on\n",
    "it\n",
    "([support@graphcore.ai](mailto:support@graphcore.ai?subject=PopXL%20Feedback)).\n",
    "Your input could help drive its future direction."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "traceability": {
   "sdk_version": "2.6.0+1074",
   "source_file": "mnist.py",
   "sst_version": "0.0.7",
   "timestamp": "2022-07-22T13:04"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
