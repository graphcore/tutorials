{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c7e9fd7",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc636b60",
   "metadata": {},
   "source": [
    "*Notebook autogenerated from mnist.py on 19-May-2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9054bfc8",
   "metadata": {},
   "source": [
    "# Training a simple TensorFlow 1 model on MNIST with an IPU\n",
    "\n",
    "This tutorial shows how to train a simple model on the MNIST numerical\n",
    "dataset on a single IPU. The dataset consists of 60,000 images of handwritten\n",
    "digits (0-9) that must be classified according to which digit they represent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef037bd",
   "metadata": {},
   "source": [
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and pre-process the MNIST dataset from Keras.\n",
    "2. Define a simple model.\n",
    "3. Define and compile the training loop.\n",
    "4. Configure the IPU system.\n",
    "5. Train the model on the IPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e5f58",
   "metadata": {},
   "source": [
    "## 1. Preparing your environment\n",
    "\n",
    "In order to run this tutorial on the IPU you will need to have:\n",
    "\n",
    "- A Poplar SDK environment enabled (see the\n",
    "[Getting Started](https://docs.graphcore.ai/en/latest/getting-started.html) guide for your IPU system).\n",
    "- The Graphcore port of TensorFlow 1 set up for the IPU (see the\n",
    "[Setup Instructions](https://docs.graphcore.ai/projects/ipu-pod-getting-started/en/latest/installation.html#setting-up-tensorflow-for-the-ipu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c72b3",
   "metadata": {},
   "source": [
    "To run the Jupyter notebook version of this tutorial:\n",
    "\n",
    "1. Enable a Poplar SDK environment\n",
    "2. In the same environment, install the Jupyter notebook server:\n",
    "`python -m pip install jupyter`\n",
    "3. Launch a Jupyter Server on a specific port:\n",
    "`jupyter-notebook --no-browser --port <port number>`\n",
    "4. Connect via SSH to your remote machine, forwarding your chosen port:\n",
    "`ssh -NL <port number>:localhost:<port number> <your username>@<remote machine>`\n",
    "\n",
    "For more details about this process, or if you need help troubleshooting,\n",
    "see our [guide on using IPUs from Jupyter notebooks](../../../tutorials/standard_tools/using_jupyter/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeeaac9",
   "metadata": {},
   "source": [
    "## 2. Import necessary libraries\n",
    "\n",
    "First of all, we need to import the Python modules that will be used in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8bbc5",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.python import ipu\n",
    "import time\n",
    "\n",
    "tf.disable_eager_execution()\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960b6e5",
   "metadata": {},
   "source": [
    "## 3. Define the hyperparameters\n",
    "\n",
    "We also need to specify the hyperparameters, which will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a09eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 32\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e2fdcf",
   "metadata": {},
   "source": [
    "## 4. Prepare dataset\n",
    "\n",
    "We can access the MNIST dataset through Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8136c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), _ = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc01de",
   "metadata": {},
   "source": [
    "The features are normalised by dividing each element of `x_train` (pixel values)\n",
    "by 255. This will make our model converge faster.\n",
    "\n",
    "We cast the labels to `int32` because other integer types are not, in general,\n",
    "supported on the IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b838b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast and normalize the training data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "y_train = y_train.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b930a166",
   "metadata": {},
   "source": [
    "We create a `tf.data.Dataset` object from the data. When batching the data, we set\n",
    "the `drop_remainder` to `True` so that all of our batches are guaranteed to have the\n",
    "same number of examples. This is important because the IPU's Poplar software stack\n",
    "does not support using tensors with shapes which are unknown when the program is\n",
    "compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb733fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build iterator over the data\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.repeat().batch(BATCHSIZE, drop_remainder=True)\n",
    "dataset_iterator = tf.data.make_initializable_iterator(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ed9ca",
   "metadata": {},
   "source": [
    "## 5. Define the model\n",
    "\n",
    "Next, we define a simple fully-connected network model using the standard Keras\n",
    "Sequential API and create an instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c505077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')])\n",
    "    return model\n",
    "\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66bc848",
   "metadata": {},
   "source": [
    "## 6. Define the loop body\n",
    "\n",
    "Now that we have the dataset and the model, we need to define a function which executes\n",
    "the main training loop.\n",
    "\n",
    "Our function outputs the loss at each step so that we can track the performance of the model.\n",
    "Because TensorFlow 1 uses lazy evaluation, we return `train_op` as well to ensure the training\n",
    "step is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_body(x, y):\n",
    "\n",
    "    logits = model(x, training=True)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.01).minimize(loss=loss)\n",
    "\n",
    "    return([loss, train_op])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e478e5f",
   "metadata": {},
   "source": [
    "## 7. Prepare the model for the IPU\n",
    "\n",
    "Now we can build an executable TensorFlow operation from the loop function, which is handled\n",
    "by `ipu.ipu_compiler.compile`. This takes a Python function computation and a list of inputs\n",
    "`inputs` and returns an operation which applies the computation to the inputs and can be run\n",
    "on an IPU device using a `sess.run` call. These inputs can be constants, `tf.placeholder`\n",
    "variables, or values from a dataset iterator. If we wish to pass inputs from a dataset iterator,\n",
    "we pass them from the `get_next()` method of the iterator.\n",
    "\n",
    "Note that we build the operation within the scope of a particular device with `ipu.scope.ipu_scope()` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a51ba",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# Get inputs from get_next() method of iterator\n",
    "(x, y) = dataset_iterator.get_next()\n",
    "\n",
    "with ipu.scopes.ipu_scope('/device:IPU:0'):\n",
    "\n",
    "    training_loop_body_on_ipu = ipu.ipu_compiler.compile(computation=training_loop_body, inputs=[x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5392c68",
   "metadata": {},
   "source": [
    "## 8. Add IPU configuration\n",
    "\n",
    "To use the IPU, we must create an IPU configuration.\n",
    "We can use `cfg.auto_select_ipus = 1` to automatically select one IPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c4316",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_configuration = ipu.config.IPUConfig()\n",
    "ipu_configuration.auto_select_ipus = 1\n",
    "ipu_configuration.configure_ipu_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7751a1",
   "metadata": {},
   "source": [
    "## 9. Execute in a TF session\n",
    "\n",
    "We can now run our training loop on an IPU using a TensorFlow session, with no further\n",
    "IPU-specific code required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59217a",
   "metadata": {
    "tags": [
     "sst_hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(dataset_iterator.initializer)\n",
    "\n",
    "    batches_per_epoch = len(x_train)//BATCHSIZE\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        loss_running_total = 0.0\n",
    "\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for batch in range(batches_per_epoch):\n",
    "\n",
    "            # This part runs on IPU since train_loop_body\n",
    "            # is placed under ipu_scope\n",
    "            loss = sess.run(training_loop_body_on_ipu)\n",
    "\n",
    "            loss_running_total += loss[0]\n",
    "\n",
    "        # Print average loss and time taken for epoch\n",
    "        print('\\n', end='')\n",
    "        print(\"Loss:\", loss_running_total/batches_per_epoch)\n",
    "        print(\"Time:\", time.time() - epoch_start_time)\n",
    "\n",
    "print(\"Program ran successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401b848",
   "metadata": {},
   "source": [
    "## Other useful resources\n",
    "\n",
    "- [TensorFlow Docs](https://docs.graphcore.ai/en/latest/software.html#tensorflow):\n",
    "all Graphcore documentation specifically relating to TensorFlow.\n",
    "\n",
    "- [IPU TensorFlow 1 Code Examples](https://github.com/graphcore/examples/tree/v2.5.0/code_examples/tensorflow):\n",
    "examples of different use cases of TensorFlow 1 on the IPU.\n",
    "\n",
    "- [Graphcore tutorials](https://github.com/graphcore/tutorials/tree/sdk-release-2.5/tutorials):\n",
    "a list of existing tutorials for using the IPU."
   ]
  }
 ],
 "metadata": {
  "traceability": {
   "sdk_version": "2.5.1+1001",
   "source_file": "mnist.py",
   "sst_version": "0.0.7",
   "timestamp": "2022-05-19T17:37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
